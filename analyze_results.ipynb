{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d8edf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13665402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/all/PalenkaLlama1-58M-strict-L0.1-H0.3_20250419_192616/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.498806338617783, 'acc_stderr,none': 0.005731827417496267, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5990337302428236, 'acc_stderr,none': 0.005262043444131852, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6933993827879917, 'acc_stderr,none': 0.0016156697990275413, 'alias': 'blimp_filtered'}}\n",
      "./results/all/PalenkaLlama1-58M-strict-L0.1-H0.5_20250419_215705/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.502875831389563, 'acc_stderr,none': 0.005731205587920797, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.6061930727592519, 'acc_stderr,none': 0.004981778196749111, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6941923683085492, 'acc_stderr,none': 0.001621555999646299, 'alias': 'blimp_filtered'}}\n",
      "./results/all/BabyLlama1-58M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.5005777851120263, 'acc_stderr,none': 0.005731039560705602, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5811987984079156, 'acc_stderr,none': 0.0053638650192445216, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6762877321878382, 'acc_stderr,none': 0.0016201880621713675, 'alias': 'blimp_filtered'}}\n",
      "./results/all/GPT2-705M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.500947265356894, 'acc_stderr,none': 0.0057314818912277765, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5740928839928726, 'acc_stderr,none': 0.005795359220820534, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6571267187390394, 'acc_stderr,none': 0.001666756925844741, 'alias': 'blimp_filtered'}}\n",
      "./results/all/PalenkaLlama1-58M-strict-L0.1-H0.1_20250419_165524/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.49976050170775643, 'acc_stderr,none': 0.005731478440750286, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5961009548383033, 'acc_stderr,none': 0.005435467110149506, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6937326785221161, 'acc_stderr,none': 0.001617432545245009, 'alias': 'blimp_filtered'}}\n",
      "./results/all/DistilledGPT-44M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.4996098324581339, 'acc_stderr,none': 0.005731590149590406, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5881333773451978, 'acc_stderr,none': 0.005254516935089517, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6579832584649832, 'acc_stderr,none': 0.001627814961227517, 'alias': 'blimp_filtered'}}\n",
      "./results/all/GPT2-small-97M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.5058740487981181, 'acc_stderr,none': 0.005729680439344307, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5627904724569255, 'acc_stderr,none': 0.005827514072562295, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6623442497474488, 'acc_stderr,none': 0.001666784887699355, 'alias': 'blimp_filtered'}}\n",
      "./results/all/Llama-360M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.4994157370961276, 'acc_stderr,none': 0.005730892922775372, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.6096254110595299, 'acc_stderr,none': 0.005478496442544517, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6539272479081184, 'acc_stderr,none': 0.0016809605895414816, 'alias': 'blimp_filtered'}}\n",
      "./results/all/GPT2-44M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.5013992722083819, 'acc_stderr,none': 0.005731566546134134, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5914632996877411, 'acc_stderr,none': 0.0055889827622152026, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6332408288445184, 'acc_stderr,none': 0.0017160755675976278, 'alias': 'blimp_filtered'}}\n",
      "./results/all/Llama-60M-strict/all_results.json\n",
      "{'ewok_filtered': {'acc,none': 0.4988863318120804, 'acc_stderr,none': 0.005731282698200574, 'alias': 'ewok_filtered'}, 'blimp_supplement': {'acc,none': 0.5668403463928995, 'acc_stderr,none': 0.005668696542283558, 'alias': 'blimp_supplement'}, 'blimp_filtered': {'acc,none': 0.6373319793963632, 'acc_stderr,none': 0.0017411363889209947, 'alias': 'blimp_filtered'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>blimp_supplement_acc</th>\n",
       "      <th>blimp_supplement_stderr</th>\n",
       "      <th>blimp_filtered_acc</th>\n",
       "      <th>blimp_filtered_stderr</th>\n",
       "      <th>ewok_filtered_acc</th>\n",
       "      <th>ewok_filtered_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BabyLlama1-58M-strict</td>\n",
       "      <td>0.581199</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.676288</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.500578</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DistilledGPT-44M-strict</td>\n",
       "      <td>0.588133</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.657983</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.499610</td>\n",
       "      <td>0.005732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT2-44M-strict</td>\n",
       "      <td>0.591463</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.633241</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.005732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT2-705M-strict</td>\n",
       "      <td>0.574093</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.657127</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.500947</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT2-small-97M-strict</td>\n",
       "      <td>0.562790</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.662344</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.505874</td>\n",
       "      <td>0.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-360M-strict</td>\n",
       "      <td>0.609625</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.653927</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.499416</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-60M-strict</td>\n",
       "      <td>0.566840</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.637332</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.498886</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PalenkaLlama1-58M-strict-L0.1-H0.1_20250419_16...</td>\n",
       "      <td>0.596101</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.693733</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.499761</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PalenkaLlama1-58M-strict-L0.1-H0.3_20250419_19...</td>\n",
       "      <td>0.599034</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.693399</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.498806</td>\n",
       "      <td>0.005732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PalenkaLlama1-58M-strict-L0.1-H0.5_20250419_21...</td>\n",
       "      <td>0.606193</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.694192</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.502876</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name  blimp_supplement_acc  \\\n",
       "0                              BabyLlama1-58M-strict              0.581199   \n",
       "1                            DistilledGPT-44M-strict              0.588133   \n",
       "2                                    GPT2-44M-strict              0.591463   \n",
       "3                                   GPT2-705M-strict              0.574093   \n",
       "4                              GPT2-small-97M-strict              0.562790   \n",
       "5                                  Llama-360M-strict              0.609625   \n",
       "6                                   Llama-60M-strict              0.566840   \n",
       "7  PalenkaLlama1-58M-strict-L0.1-H0.1_20250419_16...              0.596101   \n",
       "8  PalenkaLlama1-58M-strict-L0.1-H0.3_20250419_19...              0.599034   \n",
       "9  PalenkaLlama1-58M-strict-L0.1-H0.5_20250419_21...              0.606193   \n",
       "\n",
       "   blimp_supplement_stderr  blimp_filtered_acc  blimp_filtered_stderr  \\\n",
       "0                 0.005364            0.676288               0.001620   \n",
       "1                 0.005255            0.657983               0.001628   \n",
       "2                 0.005589            0.633241               0.001716   \n",
       "3                 0.005795            0.657127               0.001667   \n",
       "4                 0.005828            0.662344               0.001667   \n",
       "5                 0.005478            0.653927               0.001681   \n",
       "6                 0.005669            0.637332               0.001741   \n",
       "7                 0.005435            0.693733               0.001617   \n",
       "8                 0.005262            0.693399               0.001616   \n",
       "9                 0.004982            0.694192               0.001622   \n",
       "\n",
       "   ewok_filtered_acc  ewok_filtered_stderr  \n",
       "0           0.500578              0.005731  \n",
       "1           0.499610              0.005732  \n",
       "2           0.501399              0.005732  \n",
       "3           0.500947              0.005731  \n",
       "4           0.505874              0.005730  \n",
       "5           0.499416              0.005731  \n",
       "6           0.498886              0.005731  \n",
       "7           0.499761              0.005731  \n",
       "8           0.498806              0.005732  \n",
       "9           0.502876              0.005731  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_root = \"./results/all\"\n",
    "\n",
    "# Get all model folders\n",
    "folders = [f for f in os.listdir(results_root) if os.path.isdir(os.path.join(results_root, f))]\n",
    "all_results = []\n",
    "\n",
    "# Process each folder\n",
    "for folder in folders:\n",
    "    json_path = os.path.join(results_root, folder, 'all_results.json')\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Skipping {folder}, no results {json_path} file found.\")\n",
    "        continue\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        groups = data['groups']\n",
    "        print(json_path)\n",
    "        print(groups)\n",
    "        # Extract results\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"model_name\": folder,\n",
    "                \"blimp_supplement_acc\": groups[\"blimp_supplement\"][\"acc,none\"],\n",
    "                \"blimp_supplement_stderr\": groups[\"blimp_supplement\"][\"acc_stderr,none\"],\n",
    "                \"blimp_filtered_acc\": groups[\"blimp_filtered\"][\"acc,none\"],\n",
    "                \"blimp_filtered_stderr\": groups[\"blimp_filtered\"][\"acc_stderr,none\"],\n",
    "                \"ewok_filtered_acc\": groups[\"ewok_filtered\"][\"acc,none\"],\n",
    "                \"ewok_filtered_stderr\": groups[\"ewok_filtered\"][\"acc_stderr,none\"],\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "        all_results.append(df)\n",
    "\n",
    "# Combine all results\n",
    "combined_results = pd.concat(all_results, ignore_index=True)\n",
    "combined_results = combined_results.sort_values(by='model_name').reset_index(drop=True)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2414770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | model_name                                         | blimp_supplement   | blimp_filtered   | ewok_filtered   |\n",
      "|---:|:---------------------------------------------------|:-------------------|:-----------------|:----------------|\n",
      "|  0 | BabyLlama1-58M-strict                              | 0.581 ± 0.0054     | 0.676 ± 0.0016   | 0.501 ± 0.0057  |\n",
      "|  1 | DistilledGPT-44M-strict                            | 0.588 ± 0.0053     | 0.658 ± 0.0016   | 0.500 ± 0.0057  |\n",
      "|  2 | GPT2-44M-strict                                    | 0.591 ± 0.0056     | 0.633 ± 0.0017   | 0.501 ± 0.0057  |\n",
      "|  3 | GPT2-705M-strict                                   | 0.574 ± 0.0058     | 0.657 ± 0.0017   | 0.501 ± 0.0057  |\n",
      "|  4 | GPT2-small-97M-strict                              | 0.563 ± 0.0058     | 0.662 ± 0.0017   | 0.506 ± 0.0057  |\n",
      "|  5 | Llama-360M-strict                                  | 0.610 ± 0.0055     | 0.654 ± 0.0017   | 0.499 ± 0.0057  |\n",
      "|  6 | Llama-60M-strict                                   | 0.567 ± 0.0057     | 0.637 ± 0.0017   | 0.499 ± 0.0057  |\n",
      "|  7 | PalenkaLlama1-58M-strict-L0.1-H0.1_20250419_165524 | 0.596 ± 0.0054     | 0.694 ± 0.0016   | 0.500 ± 0.0057  |\n",
      "|  8 | PalenkaLlama1-58M-strict-L0.1-H0.3_20250419_192616 | 0.599 ± 0.0053     | 0.693 ± 0.0016   | 0.499 ± 0.0057  |\n",
      "|  9 | PalenkaLlama1-58M-strict-L0.1-H0.5_20250419_215705 | 0.606 ± 0.0050     | 0.694 ± 0.0016   | 0.503 ± 0.0057  |\n"
     ]
    }
   ],
   "source": [
    "# Define a helper to format \"<acc> ± <stderr>\"\n",
    "def fmt(score, stderr, score_rounding=3, stderr_rounding=4):\n",
    "    return f\"{score:.{score_rounding}f} ± {stderr:.{stderr_rounding}f}\"\n",
    "\n",
    "# Apply formatting\n",
    "combined_results['blimp_supplement'] = combined_results.apply(\n",
    "    lambda row: fmt(row['blimp_supplement_acc'], row['blimp_supplement_stderr']), axis=1\n",
    ")\n",
    "combined_results['blimp_filtered'] = combined_results.apply(\n",
    "    lambda row: fmt(row['blimp_filtered_acc'], row['blimp_filtered_stderr']), axis=1\n",
    ")\n",
    "combined_results['ewok_filtered'] = combined_results.apply(\n",
    "    lambda row: fmt(row['ewok_filtered_acc'], row['ewok_filtered_stderr']), axis=1\n",
    ")\n",
    "\n",
    "# Select only the formatted columns\n",
    "final_df = combined_results[['model_name', 'blimp_supplement', 'blimp_filtered', 'ewok_filtered']]\n",
    "\n",
    "# Print as a Markdown table\n",
    "print(final_df.to_markdown(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ffd3c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binance-calculator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
